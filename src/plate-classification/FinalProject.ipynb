{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "# Depending on library versions on your system, one of the following imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = r'digits_dataset'\n",
    "target_img_size = (32, 32) # fix image size because classification algorithms THAT WE WILL USE HERE expect that\n",
    "\n",
    "# We are going to fix the random seed to make our experiments reproducible \n",
    "# since some algorithms use pseudorandom generators\n",
    "random_seed = 42  \n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    You won't implement anything in this function. You just need to understand it \n",
    "    and understand its parameters (i.e win_size, cell_size, ... etc)\n",
    "    \"\"\"\n",
    "    img = cv2.resize(img, target_img_size)\n",
    "    win_size = (32, 32)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 9  # Number of orientation bins\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    h = h.flatten()\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through subfolders (assume folder name is the label)\n",
    "    for label_folder in os.listdir(path_to_dataset):\n",
    "        label_path = os.path.join(path_to_dataset, label_folder)\n",
    "        \n",
    "        # Ensure it's a directory (skip files)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "        \n",
    "        # Extract label from the folder name\n",
    "        label = label_folder\n",
    "        \n",
    "        # Iterate through the images in the folder\n",
    "        for img_filename in os.listdir(label_path):\n",
    "            if img_filename.lower().endswith('.jpg'):  # Process only .jpg files\n",
    "                img_path = os.path.join(label_path, img_filename)\n",
    "                \n",
    "                # Read image\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                # Extract features (e.g., HOG features)\n",
    "                features.append(extract_hog_features(img))\n",
    "                \n",
    "                # Append the label\n",
    "                labels.append(label)\n",
    "                \n",
    "                # Show an update every 1,000 images\n",
    "                if len(features) % 1000 == 0:\n",
    "                    print(f\"[INFO] Processed {len(features)} images so far.\")\n",
    "\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO understand the hyperparameters of each classifier\n",
    "classifiers = {\n",
    "    # 'SVM': svm.LinearSVC(random_state=random_seed),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=7)\n",
    "    # 'NN': MLPClassifier(solver='sgd', random_state=random_seed, hidden_layer_sizes=(500,), max_iter=20, verbose=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will test all our classifiers on a specific feature set\n",
    "def run_experiment():\n",
    "    \n",
    "    # Load dataset with extracted features\n",
    "    print('Loading dataset. This will take time ...')\n",
    "    features, labels = load_dataset()\n",
    "    print('Finished loading dataset.')\n",
    "    \n",
    "    # Since we don't want to know the performance of our classifier on images it has seen before\n",
    "    # we are going to withhold some images that we will test the classifier on after training \n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=random_seed)\n",
    "    \n",
    "    for model_name, model in classifiers.items():\n",
    "        print('############## Training', model_name, \"##############\")\n",
    "        # Train the model only on the training features\n",
    "        model.fit(train_features, train_labels)\n",
    "        \n",
    "        # Test the model on images it hasn't seen before\n",
    "        accuracy = model.score(test_features, test_labels)\n",
    "        \n",
    "        print(model_name, 'accuracy:', accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset. This will take time ...\n",
      "[INFO] Processed 1000 images so far.\n",
      "[INFO] Processed 2000 images so far.\n",
      "[INFO] Processed 3000 images so far.\n",
      "[INFO] Processed 4000 images so far.\n",
      "[INFO] Processed 5000 images so far.\n",
      "[INFO] Processed 6000 images so far.\n",
      "[INFO] Processed 7000 images so far.\n",
      "[INFO] Processed 8000 images so far.\n",
      "[INFO] Processed 9000 images so far.\n",
      "[INFO] Processed 10000 images so far.\n",
      "[INFO] Processed 11000 images so far.\n",
      "[INFO] Processed 12000 images so far.\n",
      "[INFO] Processed 13000 images so far.\n",
      "[INFO] Processed 14000 images so far.\n",
      "[INFO] Processed 15000 images so far.\n",
      "[INFO] Processed 16000 images so far.\n",
      "[INFO] Processed 17000 images so far.\n",
      "[INFO] Processed 18000 images so far.\n",
      "[INFO] Processed 19000 images so far.\n",
      "[INFO] Processed 20000 images so far.\n",
      "[INFO] Processed 21000 images so far.\n",
      "[INFO] Processed 22000 images so far.\n",
      "[INFO] Processed 23000 images so far.\n",
      "[INFO] Processed 24000 images so far.\n",
      "[INFO] Processed 25000 images so far.\n",
      "[INFO] Processed 26000 images so far.\n",
      "[INFO] Processed 27000 images so far.\n",
      "[INFO] Processed 28000 images so far.\n",
      "[INFO] Processed 29000 images so far.\n",
      "[INFO] Processed 30000 images so far.\n",
      "[INFO] Processed 31000 images so far.\n",
      "[INFO] Processed 32000 images so far.\n",
      "[INFO] Processed 33000 images so far.\n",
      "[INFO] Processed 34000 images so far.\n",
      "[INFO] Processed 35000 images so far.\n",
      "Finished loading dataset.\n",
      "############## Training KNN ##############\n",
      "KNN accuracy: 99.56338028169014 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou should get the following test accuracies the first time \\n\\nSVM accuracy ~ 97.70833333333333\\nKNN accuracy ~ 96.52777777777779\\nNN accuracy ~ 93.95833333333333\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment()\n",
    "\"\"\"\n",
    "You should get the following test accuracies the first time \n",
    "\n",
    "SVM accuracy ~ 97.70833333333333\n",
    "KNN accuracy ~ 96.52777777777779\n",
    "NN accuracy ~ 93.95833333333333\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example\n",
    "test_img_path = r'template/number3.png'\n",
    "img = cv2.imread(test_img_path)\n",
    "temp = np.copy(img)\n",
    "img [temp <= 150] = 0\n",
    "img [temp > 150] = 255\n",
    "show_images([img])\n",
    "features = extract_hog_features(img)  # be careful of the choice of feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3'], dtype='<U1')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = classifiers['KNN']\n",
    "knn.predict([features])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

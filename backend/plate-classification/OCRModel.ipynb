{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 9153 images and 9153 labels.\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.0858 - loss: 3.3592 - val_accuracy: 0.2840 - val_loss: 2.8000\n",
      "Epoch 2/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 126ms/step - accuracy: 0.3654 - loss: 2.4462 - val_accuracy: 0.6073 - val_loss: 1.3752\n",
      "Epoch 3/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 126ms/step - accuracy: 0.6009 - loss: 1.4381 - val_accuracy: 0.7389 - val_loss: 0.9929\n",
      "Epoch 4/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 153ms/step - accuracy: 0.7257 - loss: 0.9741 - val_accuracy: 0.7673 - val_loss: 0.8572\n",
      "Epoch 5/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 133ms/step - accuracy: 0.7682 - loss: 0.8164 - val_accuracy: 0.7854 - val_loss: 0.7744\n",
      "Epoch 6/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 123ms/step - accuracy: 0.7925 - loss: 0.6974 - val_accuracy: 0.7886 - val_loss: 0.7241\n",
      "Epoch 7/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 134ms/step - accuracy: 0.8176 - loss: 0.6141 - val_accuracy: 0.8007 - val_loss: 0.7201\n",
      "Epoch 8/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 157ms/step - accuracy: 0.8362 - loss: 0.5572 - val_accuracy: 0.8143 - val_loss: 0.6772\n",
      "Epoch 9/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 131ms/step - accuracy: 0.8466 - loss: 0.5063 - val_accuracy: 0.8192 - val_loss: 0.7164\n",
      "Epoch 10/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 142ms/step - accuracy: 0.8602 - loss: 0.4664 - val_accuracy: 0.8187 - val_loss: 0.7083\n",
      "Evaluating model...\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8178 - loss: 0.7622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.87%\n",
      "Model saved as chars74k_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Path to the dataset\n",
    "DATASET_PATH = \"./English/Img\"  # Chars74K dataset\n",
    "\n",
    "# Constants\n",
    "IMAGE_SIZE = (64, 64)  # Resizes images to 64x64\n",
    "NUM_CLASSES = 36  # 26 letters + 10 digits\n",
    "\n",
    "def load_chars74k(dataset_path=DATASET_PATH):\n",
    "    \"\"\"Load the Chars74K dataset and preprocess images from both GoodImg and BadImg.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Define subfolders for GoodImg and BadImg\n",
    "    folders = ['GoodImg/Bmp', 'BadImag/Bmp']\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "\n",
    "        # Iterate over all character folders in GoodImg and BadImg\n",
    "        for label, char_folder in enumerate(sorted(os.listdir(folder_path))):\n",
    "            char_folder_path = os.path.join(folder_path, char_folder)\n",
    "            if not os.path.isdir(char_folder_path):\n",
    "                continue\n",
    "\n",
    "            # Iterate over all images in the character folder\n",
    "            for img_name in os.listdir(char_folder_path):\n",
    "                img_path = os.path.join(char_folder_path, img_name)\n",
    "                img = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Resize and normalize the image\n",
    "                img = cv.resize(img, IMAGE_SIZE)\n",
    "                img = img / 255.0\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images).reshape(-1, IMAGE_SIZE[0], IMAGE_SIZE[1], 1)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def build_cnn_model(input_shape=(64, 64, 1), num_classes=NUM_CLASSES):\n",
    "    \"\"\"Build and compile a CNN model.\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def runOCR():\n",
    "    # Load and preprocess the dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    images, labels = load_chars74k()\n",
    "    print(f\"Loaded {len(images)} images and {len(labels)} labels.\")\n",
    "\n",
    "    # One-hot encode labels\n",
    "    labels = to_categorical(labels, NUM_CLASSES)\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build the CNN model\n",
    "    print(\"Building model...\")\n",
    "    model = build_cnn_model()\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Training model...\")\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating model...\")\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save the model\n",
    "    model.save(\"chars74k_model.h5\")\n",
    "    print(\"Model saved as chars74k_model.h5\")\n",
    "\n",
    "\n",
    "runOCR()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
